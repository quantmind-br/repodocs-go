{
  "url": "https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-latency.md",
  "title": "Reducing latency",
  "description": "Latency refers to the time it takes for the model to process a prompt and and generate an output. Latency can be influenced by various factors, such as the size of the model, the complexity of the prompt, and the underlying infrastructure supporting the model and point of interaction.",
  "fetched_at": "2026-01-01T02:08:23.996060398-03:00",
  "content_hash": "c31a3c759ebc7d15aca097b7fa22758ecc43a59fe9acdff0f123f9cfcd3505bf",
  "word_count": 682,
  "char_count": 4328,
  "links": [
    "https://platform.claude.com/docs/en/about-claude/glossary",
    "https://platform.claude.com/docs/en/about-claude/models/overview",
    "https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct",
    "https://platform.claude.com/docs/en/about-claude/glossary#tokens",
    "https://platform.claude.com/docs/en/api/messages",
    "https://platform.claude.com/docs/en/build-with-claude/streaming"
  ],
  "headers": {
    "h1": [
      "Reducing latency"
    ],
    "h2": [
      "How to measure latency",
      "How to reduce latency"
    ],
    "h3": [
      "1. Choose the right model",
      "2. Optimize prompt and output length",
      "3. Leverage streaming"
    ]
  },
  "rendered_with_js": false,
  "source_strategy": "llms",
  "cache_hit": true,
  "summary": "Explains strategies for optimizing model latency, emphasizing prompt engineering, model selection, and streaming to improve response speed.",
  "tags": [
    "latency-reduction",
    "prompt-engineering",
    "model-selection",
    "streaming-api",
    "response-time-optimization"
  ],
  "category": "guide"
}